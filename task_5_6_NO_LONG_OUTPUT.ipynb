{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product,chain\n",
    "from paramsearch import paramsearch\n",
    "import pandas_profiling as pp\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import catboost as cb\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep = '\\t', index_col = 'Unnamed: 0')\n",
    "test = pd.read_csv('test.csv', sep = '\\t', index_col = 'Unnamed: 0')\n",
    "\n",
    "train.drop(['140', '152', '160', '164','305', '303', '301', '193', '192', '186', '150', '141', '138', '130'],inplace = True,axis = 1)\n",
    "test.drop(['140', '152', '160', '164','305', '303', '301', '193', '192', '186', '150', '141', '138', '130'],inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "X_train_old, y_train_old = train[train.columns[1:]], train['0']\n",
    "X_test_old, y_test_old = test[test.columns[1:]], test['0'].fillna(0, inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging on log-reg\n",
    "best parameters were previously computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=0.052499, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.9, n_estimators=5, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression(class_weight = 'balanced', C = 0.052499)\n",
    "bg = BaggingClassifier(lg, random_state=42, n_estimators = 5 ,max_samples = 0.9, max_features = 1.0)\n",
    "bg.fit(X_train_old, y_train_old)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bg = bg.predict(X_test_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42, n_jobs=-1 , class_weight = 'balanced', max_features = 100, n_estimators = 500, max_depth=90, min_samples_leaf= 1)\n",
    "rfc.fit(X_train_old, y_train_old)\n",
    "\n",
    "rfc.fit(X_train_old, y_train_old)\n",
    "y_rfc = rfc.predict(X_test_old)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4, random_state=42)\n",
    "\n",
    "parameters = {'max_features': [17, 30, 35], 'min_samples_leaf': [5, 7, 10], 'max_depth': [15, 20]}\n",
    "etc = ExtraTreesClassifier(n_estimators=150, random_state=42, n_jobs=-1, class_weight = 'balanced')\n",
    "etcv = GridSearchCV(etc, parameters, n_jobs=-1, cv=skf, verbose=2, scoring='roc_auc')\n",
    "etcv.fit(X_train_old, y_train_old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
       "            criterion='gini', max_depth=20, max_features=30,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=7,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=150, n_jobs=-1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False), 0.737687976105537)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etcv.best_estimator_, etcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2525204032645223\n"
     ]
    }
   ],
   "source": [
    "best_xrf = etcv.best_estimator_\n",
    "best_xrf.fit(X_train_old, y_train_old)\n",
    "y_test = best_xrf.predict(X_test_old)\n",
    "\n",
    "#header = ['_VAL_']\n",
    "#test1 = test['0'].to_csv('bag_2.csv',sep =',', header = header, index_label = ['_ID_']).values \n",
    "\n",
    "print(np.sum(y_test)/len(y_test))\n",
    "#print(np.sum(np.abs(y_test - test1))/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf = etcv.best_estimator_\n",
    "y_xrf = best_xrf.predict(X_test_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spw = (len(y_train_old) - np.sum(y_train_old))/np.sum(y_train_old)\n",
    "gbm = xgb.XGBClassifier(n_estimators = 150, subsample=0.8, colsample_bytree=0.8, objective = 'binary:logistic', scale_pos_weight = spw)\n",
    "\n",
    "dmatrix = xgb.DMatrix(data=X_train_old, label=y_train_old)\n",
    "\n",
    "#spw = (len(y_train_old) - np.sum(y_train_old))/np.sum(y_train_old)\n",
    "\n",
    "parameters = {'learning_rate' : [0.1, 0.05], 'max_depth' : [5, 10], 'reg_lambda' : [1]}\n",
    "gbmcv = GridSearchCV(estimator = gbm, param_grid=parameters, scoring = 'roc_auc', cv = skf, verbose = 2, n_jobs = -1)\n",
    "gbmcv.fit(X_train_old, y_train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "        gamma=0, learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "        min_child_weight=1, missing=None, n_estimators=150, nthread=-1,\n",
       "        objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "        scale_pos_weight=4.624193250968099, seed=0, silent=True,\n",
       "        subsample=0.8), 0.7384816015468296)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbmcv.best_estimator_, gbmcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3170907345175228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mefkov/miniconda3/envs/py3/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "best_gbm = gbmcv.best_estimator_\n",
    "best_gbm.fit(X_train_old, y_train_old)\n",
    "y_test = best_gbm.predict(X_test_old)\n",
    "\n",
    "#header = ['_VAL_']\n",
    "#test1 = test['0'].to_csv('bag_2.csv',sep =',', header = header, index_label = ['_ID_']).values \n",
    "\n",
    "print(np.sum(y_test)/len(y_test))\n",
    "#print(np.sum(np.abs(y_test - test1))/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mefkov/miniconda3/envs/py3/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_gbm = best_gbm.predict(X_test_old)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting 1\n",
    "majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = y_bg + y_rfc + y_xrf + y_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3050888142102736"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.where(arr < 2 , 0, arr)\n",
    "arr = np.where(arr >= 2 , 1, arr)\n",
    "\n",
    "np.sum(arr)/len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['0'] = arr\n",
    "header = ['_VAL_']\n",
    "test['0'].to_csv('ensemble_4.csv',sep =',', header = header, index_label = ['_ID_']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting 2 ( Bagging, Extra trees, Random forest, Xgboost)\n",
    "rank\n",
    "\n",
    "CV -score 0.7457\n",
    "LB -score 0.691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gbm_pr = best_gbm.predict_proba(X_test_old)\n",
    "y_xrf_pr = best_xrf.predict_proba(X_test_old)\n",
    "y_rfc_pr = rfc.predict_proba(X_test_old)\n",
    "y_bg_pr = bg.predict_proba(X_test_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictions = []\n",
    "gbm_predictions = []\n",
    "xrf_predictions = []\n",
    "bg_predictions = []\n",
    "\n",
    "\n",
    "for train, val in skf.split(X_train_old, y_train_old):\n",
    "    best_gbm.fit(X_train_old.iloc[train], y_train_old[train])\n",
    "    best_xrf.fit(X_train_old.iloc[train], y_train_old[train])\n",
    "    rfc.fit(X_train_old.iloc[train], y_train_old[train])\n",
    "    bg.fit(X_train_old.iloc[train], y_train_old[train])\n",
    "    \n",
    "    \n",
    "    bg_predictions.append([y_train_old[val], bg.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "    rfc_predictions.append([y_train_old[val], rfc.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "    gbm_predictions.append([y_train_old[val], best_gbm.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "    xrf_predictions.append([y_train_old[val], best_xrf.predict_proba(X_train_old.iloc[val])[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7457898794387926"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([roc_auc_score(rf_p[0], rankdata(rf_p[1]) + rankdata(et_p[1]) + rankdata(gb_p[1]) + rankdata(bg_p[1])) for rf_p, et_p, gb_p, bg_p in zip(rfc_predictions, xrf_predictions, gbm_predictions, bg_predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.ix[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm.fit(X_train_old, y_train_old)\n",
    "best_xrf.fit(X_train_old, y_train_old)\n",
    "rfc.fit(X_train_old, y_train_old)\n",
    "bg.fit(X_train_old, y_train_old)\n",
    "\n",
    "rfc_predictions_1 = []\n",
    "gbm_predictions_1 = []\n",
    "xrf_predictions_1 = []\n",
    "bg_predictions_1 = []\n",
    "\n",
    "bg_predictions_1.append(bg.predict_proba(X_train_old)[:,1])\n",
    "rfc_predictions_1.append(rfc.predict_proba(X_train_old)[:,1])\n",
    "gbm_predictions_1.append(best_gbm.predict_proba(X_train_old)[:,1])\n",
    "xrf_predictions_1.append(best_xrf.predict_proba(X_train_old)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82073.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mefkov/miniconda3/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:17: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "t = (rankdata(rfc_predictions_1[0]) + rankdata(xrf_predictions_1[0]) + rankdata(gbm_predictions_1[0]) + rankdata(bg_predictions_1[0]))\n",
    "\n",
    "tr = Find_Optimal_Cutoff(y_train_old, t)[0]\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = tr/(max(t) - min(t))\n",
    "\n",
    "\n",
    "bg_predictions_1.append(bg.predict_proba(X_test_old)[:,1])\n",
    "rfc_predictions_1.append(rfc.predict_proba(X_test_old)[:,1])\n",
    "gbm_predictions_1.append(best_gbm.predict_proba(X_test_old)[:,1])\n",
    "xrf_predictions_1.append(best_xrf.predict_proba(X_test_old)[:,1])\n",
    "\n",
    "t_1 = (rankdata(rfc_predictions_1[0]) + rankdata(xrf_predictions_1[0]) + rankdata(gbm_predictions_1[0]) + rankdata(bg_predictions_1[0]))\n",
    "\n",
    "new_thr = coef * (max(t_1) - min(t_1)) + min(t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30196831493038884\n"
     ]
    }
   ],
   "source": [
    "t_1 = np.where(t_1 < new_thr , 0, t_1)\n",
    "t_1 = np.where(t_1 >= new_thr , 1, t_1)\n",
    "print(np.sum(t_1)/len(t_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['0'] = t_1\n",
    "header = ['_VAL_']\n",
    "test['0'].to_csv('ensemble_vote2.csv',sep =',', header = header, index_label = ['_ID_']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "дальше я тренирую новые модели(два Dart XGB, и два катбуста)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dart XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round_1 = 150\n",
    "\n",
    "params_1 = {'booster': 'dart',\n",
    "         'max_depth': 10, 'learning_rate': 0.05,\n",
    "         'objective': 'binary:logistic', 'silent': True,\n",
    "         'sample_type': 'weighted',\n",
    "         'normalize_type': 'tree',\n",
    "         'rate_drop': 0.25,\n",
    "         'subsample':0.7, 'colsample_bytree':0.7, 'eval_metric':'auc'}\n",
    "\n",
    "xgb_1 = xgb.train(params_1, dtrain, num_boost_round = num_round_1, verbose_eval = True)\n",
    "\n",
    "preds_1 = xgb_1.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round_2 = 150\n",
    "\n",
    "params_2 = {'booster': 'dart',\n",
    "         'max_depth': 7, 'learning_rate': 0.08,\n",
    "         'objective': 'binary:logistic', 'silent': True,\n",
    "         'sample_type': 'weighted',\n",
    "         'normalize_type': 'tree',\n",
    "         'rate_drop': 0.25,\n",
    "         'subsample':0.6, 'colsample_bytree':0.6, 'eval_metric':'auc'}\n",
    "\n",
    "xgb_2 = xgb.train(params_2, dtrain, num_boost_round = num_round_2, verbose_eval = True)\n",
    "\n",
    "preds_2 = xgb_2.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9734425194676225\n",
      "preds_1\n",
      "0.7316078456403736\n",
      "0.5924411740445731\n",
      "0.7652934700062765\n",
      "0.6695967345036121\n",
      "preds_2\n",
      "0.7484585306956676\n",
      "0.564183240383969\n",
      "0.7715719238095538\n",
      "0.6859181318761481\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(preds_1, preds_2)[0][1])\n",
    "print('preds_1')\n",
    "print(np.corrcoef(preds_1, y_gbm)[0][1])\n",
    "print(np.corrcoef(preds_1, y_rfc)[0][1])\n",
    "print(np.corrcoef(preds_1, y_xrf)[0][1])\n",
    "print(np.corrcoef(preds_1, y_bg)[0][1])\n",
    "print('preds_2')\n",
    "print(np.corrcoef(preds_2, y_gbm)[0][1])\n",
    "print(np.corrcoef(preds_2, y_rfc)[0][1])\n",
    "print(np.corrcoef(preds_2, y_xrf)[0][1])\n",
    "print(np.corrcoef(preds_2, y_bg)[0][1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_cols = [i for i in X_train_old.columns if len(X_train_old[i].value_counts()) == 2 ]\n",
    "\n",
    "cat_dims = [X_train_old.columns.get_loc(i) for i in category_cols[:-1]] \n",
    "\n",
    "\n",
    "# this function does 3-fold crossvalidation with catboostclassifier          \n",
    "def crossvaltest(params, train_set, train_label, cat_dims, n_splits=4, cross_val = skf):\n",
    "    #kf = KFold(n_splits=n_splits,shuffle=True)\n",
    "    kf = skf\n",
    "    res = []\n",
    "    for train_index, test_index in kf.split(train_set, train_label):\n",
    "        train = train_set.iloc[train_index,:]\n",
    "        test = train_set.iloc[test_index,:]\n",
    "\n",
    "        labels = train_label.ix[train_index]\n",
    "        test_labels = train_label.ix[test_index]\n",
    "\n",
    "        clf = cb.CatBoostClassifier(**params)\n",
    "        clf.fit(train, np.ravel(labels), cat_features=cat_dims, verbose = True)\n",
    "\n",
    "        res.append(np.mean(clf.predict(test)==np.ravel(test_labels)))\n",
    "    \n",
    "    print('res = ', np.mean(res))\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "# this function runs grid search on several parameters\n",
    "def catboost_param_tune(params, train_set, train_label, cat_dims=None, n_splits=4, cross_val = skf):\n",
    "    ps = paramsearch(params)\n",
    "    # search 'border_count', 'l2_leaf_reg' etc. individually \n",
    "    #   but 'iterations','learning_rate' together\n",
    "    for prms in chain(#ps.grid_search(['border_count']),\n",
    "                      #ps.grid_search(['ctr_border_count']),\n",
    "                      ps.grid_search(['l2_leaf_reg']),\n",
    "                      ps.grid_search(['iterations','learning_rate']),\n",
    "                      ps.grid_search(['depth'])):\n",
    "        res = crossvaltest(prms, train_set, train_label, cat_dims, n_splits, skf)\n",
    "        # save the crossvalidation result so that future iterations can reuse the best parameters\n",
    "        ps.register_result(res,prms)\n",
    "        #print(res,prms,s,'best:',ps.bestscore(),ps.bestparam())\n",
    "        print('best:',ps.bestscore(),ps.bestparam())\n",
    "    return ps.bestparam()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'depth':[5, 7],\n",
    "          'iterations':[150],\n",
    "          'learning_rate':[0.05], \n",
    "          'l2_leaf_reg':[1, 3],\n",
    "          #'border_count':[32],\n",
    "          #'ctr_border_count':[20],\n",
    "          'thread_count':4,\n",
    "          'scale_pos_weight':spw,\n",
    "          'eval_metric':'AUC'}\n",
    "\n",
    "bestparams = catboost_param_tune(params, X_train_old, y_train_old, cat_dims, 4, skf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUT: best: 0.8267212928269888 {'thread_count': 4, 'iterations': 150, 'depth': 5, 'l2_leaf_reg': 3, 'scale_pos_weight': 4.624193250968099, 'learning_rate': 0.05, 'eval_metric': 'AUC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cb1 = cb.CatBoostClassifier(**bestparams)\n",
    "clf_cb1.fit(X_train_old, np.ravel(y_train_old), cat_features = cat_dims)\n",
    "res_cb1 = clf_cb1.predict_proba(X_test_old)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7545372242555904\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(res_cb1, y_gbm)[0][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {'depth':[3],\n",
    "          'iterations':[200, 250],\n",
    "          'learning_rate':[0.1, 0.05], \n",
    "          'l2_leaf_reg':[5, 7],\n",
    "          #'border_count':[32],\n",
    "          #'ctr_border_count':[20],\n",
    "          'thread_count':4,\n",
    "          'scale_pos_weight':spw,\n",
    "          'eval_metric':'AUC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams2 = catboost_param_tune(params2, X_train_old, y_train_old, cat_dims, 4, skf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best: 0.8276066116979741 {'thread_count': 4, 'iterations': 250, 'depth': 3, 'learning_rate': 0.1, 'scale_pos_weight': 4.624193250968099, 'l2_leaf_reg': 7, 'eval_metric': 'AUC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cb2 = cb.CatBoostClassifier(**bestparams2)\n",
    "clf_cb2.fit(X_train_old, np.ravel(y_train_old), cat_features = cat_dims)\n",
    "res_cb2 = clf_cb2.predict_proba(X_test_old)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9357028235171487\n",
      "0.9796548285297352\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(res_cb2, preds_2)[0][1])\n",
    "\n",
    "print(np.corrcoef(res_cb1, res_cb2)[0][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling 1\n",
    "на всех фичах и еще предикты моделей\n",
    "\n",
    "catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictions = []\n",
    "gbm_predictions = []\n",
    "xrf_predictions = []\n",
    "bg_predictions = []\n",
    "xgb_1_predictions = []\n",
    "xgb_2_predictions = []\n",
    "clf_cb1_predictions = []\n",
    "clf_cb2_predictions = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for train, val in skf.split(X_train_old, y_train_old):\n",
    "    \n",
    "    best_gbm.fit(X_train_old.iloc[train], y_train_old[train])\n",
    "    best_xrf.fit(X_train_old.iloc[train], y_train_old[train])\n",
    "    rfc.fit(X_train_old.iloc[train], y_train_old[train])\n",
    "    bg.fit(X_train_old.iloc[train], y_train_old[train])\n",
    "    \n",
    "\n",
    "    dtrain = xgb.DMatrix(data = X_train_old.iloc[train], label = y_train_old.iloc[train])\n",
    "    dtest = xgb.DMatrix(X_train_old.iloc[val])\n",
    "\n",
    "    xgb_1 = xgb.train(params_1, dtrain, num_boost_round = num_round_1, verbose_eval = False)\n",
    "    xgb_2 = xgb.train(params_2, dtrain, num_boost_round = num_round_2, verbose_eval = False)  \n",
    "    clf_cb1.fit(X_train_old.iloc[train], np.ravel(y_train_old[train]),  cat_features = cat_dims)\n",
    "    clf_cb2.fit(X_train_old.iloc[train], np.ravel(y_train_old[train]), cat_features = cat_dims)\n",
    "    \n",
    "    preds1 = xgb_1.predict(dtest)\n",
    "    preds2 = xgb_2.predict(dtest)    \n",
    "    \n",
    "    bg_predictions.append([y_train_old[val], bg.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "    rfc_predictions.append([y_train_old[val], rfc.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "    gbm_predictions.append([y_train_old[val], best_gbm.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "    xrf_predictions.append([y_train_old[val], best_xrf.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "    \n",
    "    xgb_1_predictions.append([y_train_old[val], preds1])\n",
    "    xgb_2_predictions.append([y_train_old[val], preds2])\n",
    "    clf_cb1_predictions.append([y_train_old[val], clf_cb1.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "    clf_cb2_predictions.append([y_train_old[val], clf_cb2.predict_proba(X_train_old.iloc[val])[:,1]])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm.fit(X_train_old, y_train_old)\n",
    "best_xrf.fit(X_train_old, y_train_old)\n",
    "rfc.fit(X_train_old, y_train_old)\n",
    "bg.fit(X_train_old, y_train_old)\n",
    "    \n",
    "dtrain = xgb.DMatrix(data = X_train_old, label = y_train_old)\n",
    "dtest = xgb.DMatrix(X_test_old)\n",
    "\n",
    "xgb_1 = xgb.train(params_1, dtrain, num_boost_round = num_round_1, verbose_eval = False)\n",
    "xgb_2 = xgb.train(params_2, dtrain, num_boost_round = num_round_2, verbose_eval = False)  \n",
    "clf_cb1.fit(X_train_old, np.ravel(y_train_old),  cat_features = cat_dims)\n",
    "clf_cb2.fit(X_train_old, np.ravel(y_train_old), cat_features = cat_dims)\n",
    "rfc_preds_test = rfc.predict_proba(X_test_old)[:,1]\n",
    "xrf_preds_test = best_xrf.predict_proba(X_test_old)[:,1]\n",
    "gbm_preds_test = best_gbm.predict_proba(X_test_old)[:,1]\n",
    "bg_preds_test = bg.predict_proba(X_test_old)[:,1]\n",
    "\n",
    "xgb_1_preds_test = xgb_1.predict(dtest)\n",
    "xgb_2_preds_test = xgb_2.predict(dtest)\n",
    "clf_cb_1_preds_test = clf_cb1.predict_proba(X_test_old)[:,1]\n",
    "clf_cb_2_preds_test = clf_cb2.predict_proba(X_test_old)[:,1]\n",
    "\n",
    "\n",
    "X_test_old[\"rfc_preds\"] = rfc_preds_test\n",
    "X_test_old[\"xrf_preds\"] = xrf_preds_test\n",
    "X_test_old[\"gbm_preds\"] = gbm_preds_test\n",
    "X_test_old[\"bg_preds\"] = bg_preds_test\n",
    "\n",
    "X_test_old[\"xgb_1_preds\"] = xgb_1_preds_test\n",
    "X_test_old[\"xgb_2_preds\"] = xgb_2_preds_test\n",
    "X_test_old[\"clf_cb_1_preds\"] = clf_cb_1_preds_test\n",
    "X_test_old[\"clf_cb_2_preds\"] = clf_cb_2_preds_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_old[\"rfc_preds\"] = 0\n",
    "X_train_old[\"xrf_preds\"] = 0\n",
    "X_train_old[\"gbm_preds\"] = 0\n",
    "X_train_old[\"bg_preds\"] = 0\n",
    "\n",
    "X_train_old[\"xgb_1_preds\"] = 0\n",
    "X_train_old[\"xgb_2_preds\"] = 0\n",
    "X_train_old[\"clf_cb_1_preds\"] = 0\n",
    "X_train_old[\"clf_cb_2_preds\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "for i, fold in enumerate(skf.split(X_train_old, y_train_old)):\n",
    "    train, val = fold[0], fold[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train_old.iloc[val, -8] = rfc_predictions[i][1]\n",
    "    X_train_old.iloc[val, -7] = xrf_predictions[i][1]\n",
    "    X_train_old.iloc[val, -6] = gbm_predictions[i][1]\n",
    "    X_train_old.iloc[val, -5] = bg_predictions[i][1]\n",
    "    \n",
    "    X_train_old.iloc[val, -4] = xgb_1_predictions[i][1]\n",
    "    X_train_old.iloc[val, -3] = xgb_2_predictions[i][1]\n",
    "    X_train_old.iloc[val, -2] = clf_cb1_predictions[i][1]\n",
    "    X_train_old.iloc[val, -1] = clf_cb2_predictions[i][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {'depth':[2, 3],\n",
    "          'iterations':[200, 300],\n",
    "          'learning_rate':[0.1], \n",
    "          'l2_leaf_reg':[7],\n",
    "          #'border_count':[32],\n",
    "          #'ctr_border_count':[20],\n",
    "          'thread_count':4,\n",
    "          'scale_pos_weight':spw,\n",
    "          'eval_metric':'AUC'}\n",
    "\n",
    "bestparams3 = catboost_param_tune(params3, X_train_old, y_train_old, cat_dims, 4, skf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUT: best: 0.8298689284459584 {'thread_count': 4, 'iterations': 300, 'depth': 2, 'l2_leaf_reg': 7, 'scale_pos_weight': 4.624193250968099, 'learning_rate': 0.1, 'eval_metric': 'AUC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x127ab3828>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cb3 = cb.CatBoostClassifier(**bestparams3)\n",
    "clf_cb3.fit(X_train_old, np.ravel(y_train_old), cat_features = cat_dims)\n",
    "\n",
    "res_cb3 = clf_cb3.predict_proba(X_test_old)[:,1]\n",
    "\n",
    "yt = clf_cb3.predict_proba(X_train_old)[:,1]\n",
    "tr = Find_Optimal_Cutoff(y_train_old, yt)[0]\n",
    "\n",
    "\n",
    "res_cb3 = np.where(res_cb3 < tr , 0, res_cb3)\n",
    "res_cb3 = np.where(res_cb3 >= tr , 1, res_cb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling 2 \n",
    "на всех фичах и еще предикты моделей\n",
    "\n",
    "extra trees\n",
    "\n",
    "он и оказался лучшим на лидерборде среди всех трех ансамблей, CV - 0.7467, LB - 0.6868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_features': [5, 15, 25], 'min_samples_leaf': [1, 3, 5], 'max_depth': [5,15,20], 'class_weight':['balanced']}\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "etcv = GridSearchCV(etc, parameters, n_jobs=-1, cv=skf, verbose=2, scoring='roc_auc')\n",
    "etcv.fit(X_train_old, y_train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467941483460391"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30327868852459017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mefkov/miniconda3/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:17: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "best_et = etcv.best_estimator_\n",
    "best_et.fit(X_train_old, y_train_old)\n",
    "res_et = best_et.predict(X_test_old)\n",
    "\n",
    "yt = best_et.predict_proba(X_train_old)[:,1]\n",
    "tr = Find_Optimal_Cutoff(y_train_old, yt)[0]\n",
    "\n",
    "yt = np.where(yt < tr , 0, yt)\n",
    "yt = np.where(yt >= tr , 1, yt)\n",
    "print(np.sum(yt)/len(yt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2695631301008161\n"
     ]
    }
   ],
   "source": [
    "res_et = np.where(res_et < tr , 0, res_et)\n",
    "res_et = np.where(res_et >= tr , 1, res_et)\n",
    "print(np.sum(res_et)/len(res_et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling 2 \n",
    "\n",
    "только на предиктах других моделей\n",
    "\n",
    "(cat boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4 = {'depth':[2, 3],\n",
    "          'iterations':[150, 250],\n",
    "          'learning_rate':[0.1], \n",
    "          'l2_leaf_reg':[7],\n",
    "          #'border_count':[32],\n",
    "          #'ctr_border_count':[20],\n",
    "          'thread_count':4,\n",
    "          'scale_pos_weight':spw,\n",
    "          'eval_metric':'AUC'}\n",
    "cat_dims=[]\n",
    "\n",
    "bestparams4 = catboost_param_tune(params4, X_tr, y_tr, cat_dims, 4, skf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUT: best: 0.8300000330943708 {'thread_count': 4, 'iterations': 250, 'depth': 2, 'l2_leaf_reg': 7, 'scale_pos_weight': 4.624193250968099, 'learning_rate': 0.1, 'eval_metric': 'AUC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x118504710>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cb4 = cb.CatBoostClassifier(**bestparams4)\n",
    "clf_cb4.fit(X_tr, np.ravel(y_tr), cat_features = cat_dims)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37229956793086894\n"
     ]
    }
   ],
   "source": [
    "res_cb4 = clf_cb4.predict_proba(X_te)[:,1]\n",
    "\n",
    "\n",
    "yt = clf_cb4.predict_proba(X_tr)[:,1]\n",
    "tr = Find_Optimal_Cutoff(y_tr, yt)[0]\n",
    "\n",
    "res_cb4 = np.where(res_cb4 < tr , 0, res_cb4)\n",
    "res_cb4 = np.where(res_cb4 >= tr , 1, res_cb4)\n",
    "print(np.sum(res_cb4)/len(res_cb4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation among all ensemble predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base - ens1_catb 0.84642030854424\n",
      "base - ens1_extr 0.8965252541591218\n",
      "ens1_extr - ens1_catb 0.7825329198686126\n",
      "base - ens2_catb 0.8507852823046459\n",
      "ens1_catb - ens2_catb 0.9117924220053101\n",
      "ens1_extr - ens2_catb 0.7776133680768467\n",
      "ens1_extr - ens2_catb 0.84642030854424\n"
     ]
    }
   ],
   "source": [
    "# base = voting \n",
    "base=t_1\n",
    "print('base - ens1_catb',matthews_corrcoef(base, res_cb3))\n",
    "print('base - ens1_extr',matthews_corrcoef(base, res_et))\n",
    "print('ens1_extr - ens1_catb',matthews_corrcoef(res_et, res_cb3))\n",
    "\n",
    "#print('base - ens2_lr',matthews_corrcoef(base, y_lr))\n",
    "print('base - ens2_catb',matthews_corrcoef(base, res_cb4))\n",
    "#print('ens2_lr - ens2_catb',matthews_corrcoef(y_lr, res_cb4))\n",
    "\n",
    "print('ens1_catb - ens2_catb',matthews_corrcoef(res_cb3, res_cb4))\n",
    "\n",
    "print('ens1_extr - ens2_catb',matthews_corrcoef(res_et, res_cb4))\n",
    "print('ens1_extr - ens2_catb',matthews_corrcoef(base, res_cb3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
